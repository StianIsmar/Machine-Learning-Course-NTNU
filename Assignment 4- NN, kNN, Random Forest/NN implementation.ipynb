{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sample [1, 2, 3]\n",
      "output [[12.59486703]\n",
      " [12.77888395]]\n",
      "This is the acutal output for the NN!: [[0.99999661]\n",
      " [0.99999718]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Need to generalize it for n layers! it is generalized for n nodes in the 3 layers.\n",
    "class nn:\n",
    "    input_nodes = 0\n",
    "    hidden_nodes = 0\n",
    "    output_nodes = 0\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes # The number of features!\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        self.weights_ih = np.random.rand(self.hidden_nodes, self.input_nodes)\n",
    "        self.weights_ho = np.random.rand(self.output_nodes, self.hidden_nodes)\n",
    "\n",
    "        self.bias_h = np.empty([self.hidden_nodes, 1])\n",
    "        self.bias_o = np.empty([self.output_nodes, 1])\n",
    "        # np.random.randint(low=1, high=100, size=4)\n",
    "\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        res = 1 / (1 + np.exp(-x))\n",
    "        return res\n",
    "    \n",
    "    def feedforward(self, input_sample):\n",
    "        \n",
    "        # Generation the hidde outputs:\n",
    "        hidden = np.matrix(np.dot(self.weights_ih, input_sample)).T\n",
    "        print(\"input sample\", input_sample)\n",
    "        hidden = np.add(hidden,self.bias_h)\n",
    "       \n",
    "        sig = lambda t: self.sigmoid(t)\n",
    "        # Generate the output using the activation function:\n",
    "        output_hidden_layer = sig(hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Now, generate the output for the output layer!\n",
    "        output = np.matrix(np.dot(self.weights_ho, output_hidden_layer )).T\n",
    "        output = np.add(hidden,self.bias_o)\n",
    "        print(\"output\",output)\n",
    "        sig = lambda t: self.sigmoid(t)\n",
    "        output_output_layer = sig(output)\n",
    "        print(\"This is the acutal output for the NN!:\", output_output_layer)\n",
    "\n",
    "    \n",
    "        return 0\n",
    "            # return code\n",
    "\n",
    "    def backprop():\n",
    "        # Implement here ....\n",
    "        print(\" \")\n",
    "        \n",
    "        \n",
    "n1 = nn(3,2,1)\n",
    "n1.feedforward([1,2,3])\n",
    "\n",
    "# Store the weights in a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
